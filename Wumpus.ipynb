{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# README !!!\n",
    "# This version doesn't use a graphical interface (to avoid compatibility issues) and was tested under Python 2.7.6 and under Python 3.4.3.\n",
    "# You need to install numpy, docopt (and enum34 if under Python 2.7.*) using pip.\n",
    "# This can be done with the following commands (in a terminal in a Linux OS):\n",
    "#   If running Python 2:\n",
    "#    pip install numpy\n",
    "#    pip install docopt\n",
    "#    pip install enum34\n",
    "#   If running Python 3:\n",
    "#    pip3 install numpy\n",
    "#    pip3 install docopt\n",
    "# For this, 'pip' (or pip3) needs to be installed (which is usually already the case). If not, you can do it by installing classically python-dev (for pip) or python3-pip (for pip3), with your usual OS library management tool (yum, aptitude, apt-get, synaptic, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple program for studying RL algorithm on the Wumpus world \n",
    "CeCILL License\n",
    "\n",
    "created by Gaetan Marceau Caron   [01/02/2016]\n",
    "and updated by Guillaume Charpiat [24/02/2016]\n",
    "            \n",
    "Usage: wumpus [-i <flag>] [-t <flag>] [-w <flag>] [-v <flag>] [-d <flag>] [-g <size>] [-n <int>] [-e <int>]\n",
    "\n",
    "Options:\n",
    "-h --help      Show the description of the program\n",
    "-i <flag> --hmi <flag>  a flag for activating the graphical interface [default: True]\n",
    "-t <flag> --tore <flag>  a flag for choosing the tore grid [default: True]\n",
    "-w <flag> --wumpus_dyn <flag>  a flag for activating the Wumpus moves (beware!) [default: False]\n",
    "-v <flag> --verbose <flag>  a flag for activating the verbose mode [default: True]\n",
    "-d <flag> --display <flag>  a flag for activating the display [default: True]\n",
    "-g <size> --grid_size <size>  an integer for the grid size [default: 4] \n",
    "-n <int> --n_flash <int>  an integer for the number of power units [default: 5] \n",
    "-e <int> --max_n_iteration <int>  the maximum number of iterations [default: 100]\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#from tkinter import * \n",
    "#from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from enum import IntEnum, unique\n",
    "from docopt import docopt\n",
    "\n",
    "message = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flush_message():\n",
    "    global message\n",
    "    sys.stdout.write(message)\n",
    "    message = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@unique\n",
    "class Action(IntEnum):\n",
    "    UP = 1\n",
    "    DOWN = 2\n",
    "    LEFT = 3\n",
    "    RIGHT = 4\n",
    "    FLASH_UP = 5\n",
    "    FLASH_DOWN = 6\n",
    "    FLASH_LEFT = 7\n",
    "    FLASH_RIGHT = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        pass\n",
    "        \n",
    "    def getAction(self):\n",
    "        return Action(np.random.randint(1,len(Action)+1))\n",
    "    \n",
    "    def getPosition(self):\n",
    "        return self.state_[:2]\n",
    "\n",
    "    def getState(self):\n",
    "        return self.state_\n",
    "\n",
    "    def nextState(self,s,reward):\n",
    "        self.state_ = s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftmaxAgent:\n",
    "\n",
    "    def __init__(self, A, beta):\n",
    "        self.beta = beta\n",
    "        self.A = A\n",
    "        self.counts = [0] * self.A  \n",
    "        self.values = [0.] * self.A\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def getAction(self):\n",
    "        z = sum([math.exp(v / self.beta) for v in self.values])\n",
    "        probs = [math.exp(v / self.beta) / z for v in self.values]\n",
    "        return np.argmax(probs)\n",
    "    \n",
    "    def getPosition(self):\n",
    "        return self.state_[:2]\n",
    "\n",
    "    def getState(self):\n",
    "        return self.state_\n",
    "\n",
    "    def nextState(self,s,reward):\n",
    "        self.state_ = s\n",
    "    \n",
    "    def interact(self):\n",
    "        z = sum([math.exp(v / self.beta) for v in self.values])\n",
    "        probs = [math.exp(v / self.beta) / z for v in self.values]\n",
    "        return np.argmax(probs)\n",
    "\n",
    "    def update(self, chosen_arm, r):\n",
    "        self.counts[chosen_arm] = self.counts[chosen_arm] + 1\n",
    "        n = self.counts[chosen_arm]\n",
    "        value = self.values[chosen_arm]\n",
    "        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * r\n",
    "        self.values[chosen_arm] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "\n",
    "    def __init__(self, agent, my_args=None):\n",
    "        self.grid_size_ = (int(my_args[\"--grid_size\"]),int(my_args[\"--grid_size\"]))\n",
    "        self.hole_pos_ = (1,1)\n",
    "        self.treasure_pos_ = (self.grid_size_[0]-1,self.grid_size_[1]-1)\n",
    "\n",
    "        self.agent = agent\n",
    "\n",
    "        self.DEFAULT_N_FLASH = int(my_args[\"--n_flash\"])\n",
    "        self.DEFAULT_REWARD = -1.\n",
    "        self.KILL_REWARD = 5.\n",
    "        self.TREASURE_REWARD = 100.\n",
    "        self.HOLE_REWARD = -10.\n",
    "        self.WUMPUS_REWARD = -10.\n",
    "        self.TORE_TOPO = (my_args[\"--tore\"]==\"True\")\n",
    "        self.DYN_WUMPUS = (my_args[\"--wumpus_dyn\"]==\"True\")\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.agent.reset()\n",
    "        init_state = self.getInitState()\n",
    "        self.agent.nextState(init_state, 0.)\n",
    "        self.wumpus_pos_ = [1,2]\n",
    "        print(\"\\n **** New start **** \\n\")\n",
    "\n",
    "    def getInitState(self):\n",
    "        return [0,0,0,0,self.DEFAULT_N_FLASH]    \n",
    "        # An agent state is : (x coordinate, y coordinate, smell the Wumpus?, feel breeze?, remaining number of shots)\n",
    "        \n",
    "    def getGridSize(self):\n",
    "        return self.grid_size_\n",
    "\n",
    "    def getWumpusPosition(self):\n",
    "        return self.wumpus_pos_\n",
    "\n",
    "    def getHolePosition(self):\n",
    "        return self.hole_pos_\n",
    "\n",
    "    def getTreasurePosition(self):\n",
    "        return self.treasure_pos_\n",
    "\n",
    "    def getNFlash(self):\n",
    "        return self.n_flash_\n",
    "    \n",
    "    def moveWumpus(self):\n",
    "        a = Action(np.random.randint(1,4)) #Warning hardcoded value!\n",
    "        self.wumpus_pos_ = self.moveAgent(self.wumpus_pos_,a)\n",
    "\n",
    "    def moveAgent(self, curr_pos, a):\n",
    "        next_pos = []\n",
    "        if a == Action.UP:\n",
    "            next_pos = [curr_pos[0], curr_pos[1]+1]\n",
    "        elif a == Action.DOWN:\n",
    "            next_pos = [curr_pos[0], curr_pos[1]-1]\n",
    "        elif a == Action.LEFT:\n",
    "            next_pos = [curr_pos[0]-1, curr_pos[1]]\n",
    "        elif a == Action.RIGHT:\n",
    "            next_pos = [curr_pos[0]+1, curr_pos[1]]\n",
    "\n",
    "        if not self.TORE_TOPO:\n",
    "            next_pos = [min(self.grid_size_[0]-1,next_pos[0]),  min(self.grid_size_[1]-1,next_pos[1])]\n",
    "            next_pos = [max(0,next_pos[0]),  max(0,next_pos[1])]\n",
    "        else:\n",
    "            if next_pos[0] == self.grid_size_[0]:\n",
    "                next_pos = [0, next_pos[1]]\n",
    "            elif next_pos[0] == -1:\n",
    "                next_pos = [self.grid_size_[0]-1, next_pos[1]]\n",
    "\n",
    "            if next_pos[1] == self.grid_size_[1]:\n",
    "                next_pos = [next_pos[0], 0]\n",
    "            elif next_pos[1] == -1:\n",
    "                next_pos = [next_pos[0], self.grid_size_[1]-1]\n",
    "\n",
    "        return next_pos \n",
    "            \n",
    "    def flashAgent(self, s, a):\n",
    "        agent_pos = s[:2]\n",
    "        n_flash = s[4]\n",
    "        if n_flash > 0 and self.wumpus_pos_[0] >= 0:\n",
    "            if a == Action.FLASH_UP:\n",
    "                if self.wumpus_pos_[0] == agent_pos[0] and self.wumpus_pos_[1] == agent_pos[1]+1:\n",
    "                    self.wumpus_pos_ = [-1,-1]\n",
    "                    return True\n",
    "            elif a == Action.FLASH_DOWN:\n",
    "                if self.wumpus_pos_[0] == agent_pos[0] and self.wumpus_pos_[1] == agent_pos[1]-1:\n",
    "                    self.wumpus_pos_ = [-1,-1]\n",
    "                    return True\n",
    "            elif a == Action.FLASH_LEFT: \n",
    "                if self.wumpus_pos_[0] == agent_pos[0]-1 and self.wumpus_pos_[1] == agent_pos[1]:\n",
    "                    self.wumpus_pos_ = [-1,-1]\n",
    "                    return True\n",
    "            elif a == Action.FLASH_RIGHT:\n",
    "                if self.wumpus_pos_[0] == agent_pos[0]+1 and self.wumpus_pos_[1] == agent_pos[1]:\n",
    "                    self.wumpus_pos_ = [-1,-1]\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def testForEnd(self, s):\n",
    "        global message\n",
    "        agent_pos = s[:2]\n",
    "        if self.wumpus_pos_[0] == agent_pos[0] and self.wumpus_pos_[1] == agent_pos[1]:\n",
    "            message += \"\\n ---- Met the Wumpus... and died ---- \\n\"\n",
    "            return (self.WUMPUS_REWARD, True) \n",
    "        elif self.hole_pos_[0] == agent_pos[0] and self.hole_pos_[1] == agent_pos[1]:\n",
    "            message += \"\\n ---- Stepped in a hole... and died ---- \\n\"\n",
    "            return (self.HOLE_REWARD, True)\n",
    "        elif self.treasure_pos_[0] == agent_pos[0] and self.treasure_pos_[1] == agent_pos[1]:\n",
    "            message += \"\\n ---- Found the treasure ! ---- \\n\"\n",
    "            return (self.TREASURE_REWARD, True)\n",
    "        else:\n",
    "            return (0, False)\n",
    "        \n",
    "    def updateSense(self, agent_pos):\n",
    "        [smell,breeze] = [0,0]\n",
    "        if abs(self.wumpus_pos_[0] - agent_pos[0]) + abs(self.wumpus_pos_[1] - agent_pos[1])<2:\n",
    "            smell = 1\n",
    "        if abs(self.hole_pos_[0] - agent_pos[0]) + abs(self.hole_pos_[1] - agent_pos[1])<2:\n",
    "            breeze = 1\n",
    "        return [smell,breeze]\n",
    "    \n",
    "    def nextState(self):\n",
    "        a = self.agent.getAction()\n",
    "        s = self.agent.getState()\n",
    "        reward = self.DEFAULT_REWARD\n",
    "        global message\n",
    "        \n",
    "        next_agent_pos = s[:2]\n",
    "        n_flash = s[-1]\n",
    "        if a < 5:\n",
    "            next_agent_pos = self.moveAgent(s[:2], a)\n",
    "        else:\n",
    "            if n_flash > 0:\n",
    "                n_flash -= 1\n",
    "                flash_success = self.flashAgent(s, a)\n",
    "                if flash_success:\n",
    "                    reward += self.KILL_REWARD\n",
    "                    message += \"\\n ---- Killed the Wumpus ! ---- \\n\"\n",
    "            \n",
    "        if self.DYN_WUMPUS:\n",
    "            self.moveWumpus()\n",
    "\n",
    "        sense = self.updateSense(next_agent_pos)\n",
    "        new_state = next_agent_pos+sense+[n_flash]\n",
    "        (end_reward, end_flag) = self.testForEnd(new_state)\n",
    "        \n",
    "        return (new_state, a, reward+end_reward, end_flag)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WumpusTextHMI:\n",
    "\n",
    "    def __init__(self, my_args=None):\n",
    "        self.DELTA_TIME = 1\n",
    "        self.char_per_box = 1\n",
    "        self.draw_contours = True\n",
    "        self.LOGGER_TIME_STEP = (my_args[\"--verbose\"]==\"True\")\n",
    "        self.DISPLAY = (my_args[\"--display\"]==\"True\")\n",
    "        self.agent = Agent()\n",
    "        self.reset()\n",
    "        self.environment = Environment(self.agent,my_args)\n",
    "        self.agent_prev_pos = self.agent.getPosition()\n",
    "        self.wumpus_prev_pos = self.environment.getWumpusPosition()\n",
    "        if (self.DISPLAY):\n",
    "            self.loadImages()\n",
    "            self.displayWorld()\n",
    "\n",
    "    def loadImages(self):\n",
    "        self.image_wumpus = 'W'\n",
    "        self.image_hole = 'O'\n",
    "        self.image_treasure = '$'\n",
    "        self.image_hunter = '+'\n",
    "\n",
    "    def convertCoord(self,pos):\n",
    "        grid_size = self.environment.getGridSize()\n",
    "        return (grid_size[1] - pos[1] - 1, pos[0])\n",
    "    \n",
    "    def displayWorld(self):\n",
    "        line_width = (self.char_per_box + 1) * self.environment.getGridSize()[1] + 1\n",
    "        horizontal_line =  '-' * line_width\n",
    "        print('\\n')\n",
    "        if self.draw_contours:\n",
    "            print(horizontal_line)\n",
    "\n",
    "        for line in range(self.environment.getGridSize()[0]):\n",
    "            if self.draw_contours:\n",
    "                sys.stdout.write('|')\n",
    "            for col in range(self.environment.getGridSize()[1]):\n",
    "                letter = ' '\n",
    "\n",
    "                if (line,col) == self.convertCoord(self.environment.getWumpusPosition()):\n",
    "                    letter = self.image_wumpus\n",
    "\n",
    "                if (line,col) == self.convertCoord(self.environment.getHolePosition()):\n",
    "                    letter = self.image_hole\n",
    "\n",
    "                if (line,col) == self.convertCoord(self.environment.getTreasurePosition()):\n",
    "                    letter = self.image_treasure\n",
    "\n",
    "                if (line,col) == self.convertCoord(self.agent.getPosition()):\n",
    "                    letter = self.image_hunter\n",
    "\n",
    "                sys.stdout.write(letter)\n",
    "                if self.draw_contours:\n",
    "                    sys.stdout.write('|')\n",
    "\n",
    "            sys.stdout.write('\\n')\n",
    "            if self.draw_contours:\n",
    "                print(horizontal_line)\n",
    "\n",
    "        sys.stdout.write('\\n')\n",
    "\n",
    "                    \n",
    "    def reset(self):\n",
    "        self.time_step_ = 0\n",
    "        self.cumul_reward_ = 0\n",
    "    \n",
    "    def updateLoop(self):\n",
    "        self.agent_prev_pos = self.agent.getPosition()\n",
    "        self.wumpus_prev_pos = self.environment.getWumpusPosition()\n",
    "        prev_state = self.agent.getState()\n",
    "        (new_state, a, reward, end_flag) = self.environment.nextState()\n",
    "        self.agent.nextState(new_state,reward)\n",
    "\n",
    "        self.time_step_ += 1\n",
    "        self.cumul_reward_ += reward\n",
    "        if(self.LOGGER_TIME_STEP):\n",
    "            print(\"time step \" + str(self.time_step_) + \" : state \" + str(prev_state) + \" with \" + str(a) + \" ==> new state \" + str(self.agent.getState()) + \"; cumulated reward \" + str(self.cumul_reward_))\n",
    "\n",
    "        if (self.DISPLAY):\n",
    "            flush_message()\n",
    "\n",
    "        if(end_flag):\n",
    "            print(\"\\n **** End of episode at time step \" + str(self.time_step_) + \" \" + str(self.cumul_reward_) + \" ****\")\n",
    "            self.reset()\n",
    "            self.environment.reset()\n",
    "\n",
    "\n",
    "        if (self.DISPLAY):\n",
    "            sleep(self.DELTA_TIME)   # only for human-intended display: to be removed to go faster\n",
    "            self.displayWorld()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generic platform\n",
    "\n",
    "class RLPlatform:\n",
    "\n",
    "    def __init__(self,my_args):\n",
    "        self.LOGGER_TIME_STEP = (my_args[\"--verbose\"]==\"True\")\n",
    "        self.agent = Agent()\n",
    "        self.reset()\n",
    "        self.environment = Environment(self.agent,my_args)\n",
    "        self.agent_prev_pos = self.agent.getPosition()\n",
    "\n",
    "    def reset(self):\n",
    "        self.time_step_ = 0\n",
    "        self.cumul_reward_ = 0\n",
    "    \n",
    "    def updateLoop(self):\n",
    "        self.agent_prev_pos = self.agent.getPosition()\n",
    "        prev_state = self.agent.getState()\n",
    "        (new_state, a, reward,end_flag) = self.environment.nextState()\n",
    "        self.agent.nextState(new_state,reward)\n",
    "\n",
    "        self.time_step_ += 1\n",
    "        self.cumul_reward_ += reward\n",
    "        if(self.LOGGER_TIME_STEP):\n",
    "            print(\"time step \" + str(self.time_step_) + \" \" + str(prev_state) + \" \" + str(a) + \" \" + str(self.agent.getState()) + \" \" + str(self.cumul_reward_))\n",
    "\n",
    "        if(end_flag):\n",
    "            print(\"End of episode at time step \" + str(self.time_step_) + \" \" + str(self.cumul_reward_))\n",
    "            self.reset()\n",
    "            self.environment.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DocoptExit",
     "evalue": "Usage: wumpus [-i <flag>] [-t <flag>] [-w <flag>] [-v <flag>] [-d <flag>] [-g <size>] [-n <int>] [-e <int>]",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mDocoptExit\u001b[0m\u001b[0;31m:\u001b[0m Usage: wumpus [-i <flag>] [-t <flag>] [-w <flag>] [-v <flag>] [-d <flag>] [-g <size>] [-n <int>] [-e <int>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordan\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Retrieve the arguments from the command-line\n",
    "    my_args = docopt(__doc__)\n",
    "    print(my_args)\n",
    "\n",
    "    if my_args[\"--hmi\"]==\"True\":\n",
    "        platform = WumpusTextHMI(my_args)\n",
    "    else:\n",
    "        platform = RLPlatform(my_args)\n",
    "\n",
    "    for i in range(int(my_args[\"--max_n_iteration\"])):\n",
    "        platform.updateLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
